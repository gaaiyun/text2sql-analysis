"""
ç½‘ç»œæœç´¢é›†æˆå·¥å…·
èžåˆäº’è”ç½‘ä¿¡æ¯æ£€ç´¢ï¼Œè¡¥å……æ•°æ®åº“æŸ¥è¯¢ç»“æžœ

ä½¿ç”¨æ–¹æ³•:
    python web_search.py "äººå·¥æ™ºèƒ½è¡Œä¸šå‘å±•è¶‹åŠ¿"
"""

from duckduckgo_search import DDGS
import json
import sys

def search_web(query, max_results=5, time_range='year'):
    """
    æœç´¢ç½‘ç»œä¿¡æ¯
    
    å‚æ•°:
        query: æœç´¢å…³é”®è¯
        max_results: æœ€å¤§ç»“æžœæ•°ï¼ˆé»˜è®¤ 5ï¼‰
        time_range: æ—¶é—´èŒƒå›´ ('day', 'week', 'month', 'year')
    
    è¿”å›ž:
        list of dictï¼ŒåŒ…å«æ ‡é¢˜ã€æ‘˜è¦ã€é“¾æŽ¥
    """
    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(
                query, 
                max_results=max_results,
                timelimit=time_range
            ))
        
        formatted_results = []
        for r in results:
            formatted_results.append({
                'title': r.get('title', ''),
                'snippet': r.get('body', ''),
                'url': r.get('href', ''),
                'source': r.get('href', '').split('/')[2] if r.get('href') else ''
            })
        
        return formatted_results
    except Exception as e:
        print(f"âŒ æœç´¢å¤±è´¥: {e}")
        return []

def search_news(query, max_results=3):
    """æœç´¢æ–°é—»"""
    try:
        with DDGS() as ddgs:
            results = list(ddgs.news(query, max_results=max_results))
        
        formatted_results = []
        for r in results:
            formatted_results.append({
                'title': r.get('title', ''),
                'snippet': r.get('body', ''),
                'url': r.get('url', ''),
                'date': r.get('date', ''),
                'source': r.get('source', '')
            })
        
        return formatted_results
    except Exception as e:
        print(f"âŒ æ–°é—»æœç´¢å¤±è´¥: {e}")
        return []

def enhance_analysis(db_data, search_query):
    """
    å¢žå¼ºåˆ†æž - ç»“åˆæ•°æ®åº“ç»“æžœå’Œç½‘ç»œæœç´¢
    
    å‚æ•°:
        db_data: æ•°æ®åº“æŸ¥è¯¢ç»“æžœ
        search_query: æœç´¢å…³é”®è¯
    
    è¿”å›ž:
        dict åŒ…å«æ•°æ®åº“æ•°æ® + ç½‘ç»œæœç´¢ç»“æžœ + ç»¼åˆåˆ†æž
    """
    print(f"ðŸ” æœç´¢: {search_query}")
    
    # æ‰§è¡Œç½‘ç»œæœç´¢
    web_results = search_web(search_query, max_results=5)
    news_results = search_news(search_query, max_results=3)
    
    # æ•´åˆç»“æžœ
    enhanced = {
        'database_data': db_data,
        'web_insights': web_results,
        'news_updates': news_results,
        'summary': generate_summary(db_data, web_results)
    }
    
    return enhanced

def generate_summary(db_data, web_results):
    """ç”Ÿæˆç»¼åˆåˆ†æžæ‘˜è¦"""
    summary = []
    
    # ä»Žç½‘ç»œç»“æžœæå–å…³é”®ä¿¡æ¯
    key_points = []
    for result in web_results[:3]:
        snippet = result.get('snippet', '')
        if len(snippet) > 50:
            key_points.append(snippet[:150] + '...')
    
    summary = {
        'key_findings': key_points,
        'data_sources': ['è‡ªæœ‰æ•°æ®åº“', 'äº’è”ç½‘æœç´¢'],
        'confidence': 'é«˜' if len(web_results) >= 3 else 'ä¸­'
    }
    
    return summary

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python web_search.py \"æœç´¢å…³é”®è¯\"")
        sys.exit(1)
    
    query = sys.argv[1]
    results = search_web(query)
    
    print(f"\nðŸ” æœç´¢ç»“æžœ ({len(results)} æ¡):\n")
    for idx, r in enumerate(results, 1):
        print(f"{idx}. {r['title']}")
        print(f"   {r['snippet'][:100]}...")
        print(f"   æ¥æº: {r['source']}\n")
